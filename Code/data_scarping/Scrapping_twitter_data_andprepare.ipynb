{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Scrapping Data\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "87fteEEcoQoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snscrape\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "NRH_-JrAocPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scrape data about ai and neuroscience\n",
        "query = \"ai and neuroscience\"\n",
        "tweets = []\n",
        "limit = 50000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('ai_neuroscience_tweets.csv')"
      ],
      "metadata": {
        "id": "-AYMW_JfoVgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "b_7ol_dgoQl1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqMZo54FTCLd",
        "outputId": "59e8ad62-09bb-4cf2-a1fd-ad368c397327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spark in /usr/local/lib/python3.8/dist-packages (0.2.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: findspark in /usr/local/lib/python3.8/dist-packages (2.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.8/dist-packages (3.3.2)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.8/dist-packages (from pyspark) (0.10.9.5)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.8/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.8/dist-packages (from textblob) (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install spark \n",
        "!pip install findspark \n",
        "!pip install pyspark\n",
        "!pip install textblob\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libaraies\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Yhw0utrSTToV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "import pyspark as ps\n",
        "import warnings\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.sql.types import DoubleType\n",
        "from textblob import TextBlob\n",
        "from pyspark.sql.functions import udf , col,lit"
      ],
      "metadata": {
        "id": "EpR-zUOcTV9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Data \n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VdmZ0sHuTPIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # create SparkContext on all CPUs available: in my case I have 4 CPUs on my laptop\n",
        "    sc = ps.SparkContext('local[4]')\n",
        "    sqlContext = SQLContext(sc)\n",
        "    print(\"Just created a SparkContext\")\n",
        "except ValueError:\n",
        "    warnings.warn(\"SparkContext already exists in this scope\")\n",
        "\n",
        "print(sc.master)\n",
        "df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('/content/ai_neuroscience_tweets.csv')   \n",
        "print(type(df))\n",
        "print(\"data count \" ,df.count())\n",
        "print(df.show())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvlElQSUTOM_",
        "outputId": "36266658-ad6c-46ad-be37-01e19350d0e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Just created a SparkContext\n",
            "local[4]\n",
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "data count  36106\n",
            "+--------------------+--------------------+\n",
            "|                 _c0|               tweet|\n",
            "+--------------------+--------------------+\n",
            "|                   0|@cryptoworld202 Y...|\n",
            "|After years of bu...| #Matrix is initi...|\n",
            "|Data from the bra...| stored and proce...|\n",
            "|                   1|@MatrixAINetwork ...|\n",
            "|#AI #metaverse #w...|                null|\n",
            "|                   2|@Metathea11 Yeah ...|\n",
            "|I studied neurosc...|   I love philosophy|\n",
            "|Which is why it’s...|                null|\n",
            "|                   3|✨Safeguarding mem...|\n",
            "|#OasisNetwork and...|                null|\n",
            "|Privacy and confi...|                null|\n",
            "|Control your data...|                null|\n",
            "|                   4|Interested in lea...|\n",
            "|https://t.co/EkIC...|                null|\n",
            "|                   5|@PessoaBrain Lear...|\n",
            "|                   6|Stanford's @stanf...|\n",
            "|Information and a...|                null|\n",
            "|                   7|@WhaleEverything ...|\n",
            "|After years of bu...| #Matrix is blend...|\n",
            "|                   8|@CryptoThro You c...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check Null \n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "IgE_mUqzUA_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.select(df[\"tweet\"])\n",
        "print(\"Count Null values in data \" , df.filter(df.tweet.isNull()).count())\n",
        "data_withoutnull = df.filter(df.tweet.isNotNull()).dropna()\n",
        "print(\"Count Null values in data after removing null  \" , data_withoutnull.filter(data_withoutnull.tweet.isNull()).count())\n",
        "print(\"Count data after removing null  \" , data_withoutnull.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vrp4-oo0Tx_u",
        "outputId": "04b4023c-b5f1-428d-bad3-a9fbe72f9f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count Null values in data  11530\n",
            "Count Null values in data after removing null   0\n",
            "Count data after removing null   24576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Duplicates"
      ],
      "metadata": {
        "id": "F-tnsCixUkAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"count of data before removing duplications :\" , data_withoutnull.count())\n",
        "print(\"Distinct count: \"+str(data_withoutnull.distinct().count()))\n",
        "#Remove Duplicates \n",
        "tweets_distinct = data_withoutnull.dropDuplicates()\n",
        "print(\"count of data after removing duplications : \"+str(tweets_distinct.count()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZplqI8BqVVNP",
        "outputId": "f95d8ded-cc08-447a-e4e9-f0101065171c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count of data before removing duplications : 24576\n",
            "Distinct count: 23003\n",
            "count of data after removing duplications : 23003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label data \n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "nTPV2fCwV8B2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get sentiment\n",
        "def apply_blob(sentence):\n",
        "    temp = TextBlob(sentence).sentiment[0]\n",
        "    if temp == 0.0:\n",
        "        return 0.0 # Neutral\n",
        "    elif temp >= 0.0:\n",
        "        return 1.0 # Positive\n",
        "    else:\n",
        "        return 2.0 # Negative\n",
        "\n",
        "# UDF to write sentiment on DF\n",
        "sentiment = udf(apply_blob, DoubleType())\n",
        "\n",
        "data = tweets_distinct.select(lit( sentiment(tweets_distinct['tweet'])).alias(\"label\"), \"*\")\n",
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i-xB7KTVmrO",
        "outputId": "04502478-3b70-45e8-de95-ceee52bdb78f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|               tweet|\n",
            "+-----+--------------------+\n",
            "|  1.0|@cz_binance 🔹 Ma...|\n",
            "|  1.0|As a layman, the ...|\n",
            "|  0.0|📣MAIN2022 call f...|\n",
            "|  0.0|I think @DavidAMa...|\n",
            "|  1.0|@gershbrain We ke...|\n",
            "+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Other CSV options\n",
        "data.write.options(header='True', delimiter=',').csv(\"preprocessing_twitter_Scrapping_data_\")"
      ],
      "metadata": {
        "id": "DnHrzYE5QQ-X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}